{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e1224d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. Write a python program to extract the video URL of the first five videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82a4106",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Replace with the actual URL of the page you want to scrape\n",
    "url = 'https://example.com/videos'\n",
    "\n",
    "# Fetch the webpage\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()  # Raise an error for bad responses\n",
    "\n",
    "# Parse the HTML content\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Find all video elements (this will depend on the actual HTML structure)\n",
    "# Here, we're assuming videos are contained in <a> tags with a class of 'video-link'\n",
    "video_links = soup.find_all('a', class_='video-link', limit=5)\n",
    "\n",
    "# Extract and print the URLs\n",
    "video_urls = []\n",
    "for link in video_links:\n",
    "    video_url = link['href']  # or link.get('href')\n",
    "    video_urls.append(video_url)\n",
    "\n",
    "# Output the video URLs\n",
    "for i, url in enumerate(video_urls, start=1):\n",
    "    print(f\"Video {i} URL: {url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5880127e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2. Write a python program to extract the URL of the video thumbnails of the first five videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e533cbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Replace with the actual URL of the page you want to scrape\n",
    "url = 'https://example.com/videos'\n",
    "\n",
    "# Fetch the webpage\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()  # Raise an error for bad responses\n",
    "\n",
    "# Parse the HTML content\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Find all thumbnail elements (modify the tag and class as needed)\n",
    "# Here we're assuming thumbnails are contained in <img> tags with a class of 'thumbnail'\n",
    "thumbnail_links = soup.find_all('img', class_='thumbnail', limit=5)\n",
    "\n",
    "# Extract and print the URLs of the thumbnails\n",
    "thumbnail_urls = []\n",
    "for img in thumbnail_links:\n",
    "    thumbnail_url = img['src']  # or img.get('src')\n",
    "    thumbnail_urls.append(thumbnail_url)\n",
    "\n",
    "# Output the thumbnail URLs\n",
    "for i, url in enumerate(thumbnail_urls, start=1):\n",
    "    print(f\"Thumbnail {i} URL: {url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708a7ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3. Write a python program to extract the title of the first five videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b02a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Replace with the actual URL of the page you want to scrape\n",
    "url = 'https://example.com/videos'\n",
    "\n",
    "# Fetch the webpage\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()  # Raise an error for bad responses\n",
    "\n",
    "# Parse the HTML content\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Find all video title elements (modify the tag and class as needed)\n",
    "# Here we're assuming titles are contained in <h2> tags with a class of 'video-title'\n",
    "video_titles = soup.find_all('h2', class_='video-title', limit=5)\n",
    "\n",
    "# Extract and print the titles\n",
    "titles = []\n",
    "for title in video_titles:\n",
    "    titles.append(title.get_text(strip=True))  # Strip whitespace\n",
    "\n",
    "# Output the video titles\n",
    "for i, title in enumerate(titles, start=1):\n",
    "    print(f\"Video {i} Title: {title}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c241ec42",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4. Write a python program to extract the number of views of the first five videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940c349f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Replace with the actual URL of the page you want to scrape\n",
    "url = 'https://example.com/videos'\n",
    "\n",
    "# Fetch the webpage\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()  # Raise an error for bad responses\n",
    "\n",
    "# Parse the HTML content\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Find all video view count elements (modify the tag and class as needed)\n",
    "# Here we're assuming views are contained in <span> tags with a class of 'view-count'\n",
    "view_counts = soup.find_all('span', class_='view-count', limit=5)\n",
    "\n",
    "# Extract and print the view counts\n",
    "views = []\n",
    "for view in view_counts:\n",
    "    views.append(view.get_text(strip=True))  # Strip whitespace\n",
    "\n",
    "# Output the view counts\n",
    "for i, view in enumerate(views, start=1):\n",
    "    print(f\"Video {i} Views: {view}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31e5f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5. Write a python program to extract the time of posting of video for the first five videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f76927",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Replace with the actual URL of the page you want to scrape\n",
    "url = 'https://example.com/videos'\n",
    "\n",
    "# Fetch the webpage\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()  # Raise an error for bad responses\n",
    "\n",
    "# Parse the HTML content\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Find all posting time elements (modify the tag and class as needed)\n",
    "# Here we're assuming the posting time is contained in <time> tags with a class of 'post-time'\n",
    "posting_times = soup.find_all('time', class_='post-time', limit=5)\n",
    "\n",
    "# Extract and print the posting times\n",
    "times = []\n",
    "for time in posting_times:\n",
    "    times.append(time.get_text(strip=True))  # Strip whitespace\n",
    "\n",
    "# Output the posting times\n",
    "for i, time in enumerate(times, start=1):\n",
    "    print(f\"Video {i} Posted At: {time}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
