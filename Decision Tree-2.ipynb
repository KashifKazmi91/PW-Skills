{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ba48a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "You are a data scientist working for a healthcare company, and you have been tasked with creating a\n",
    "decision tree to help identify patients with diabetes based on a set of clinical variables. You have been\n",
    "given a dataset (diabetes.csv) with the following variables:\n",
    "1. Pregnancies: Number of times pregnant (integer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a308d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('diabetes.csv')\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(data.head())\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Check for missing values\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Visualize the distribution of the target variable\n",
    "sns.countplot(x='Outcome', data=data)\n",
    "plt.title('Distribution of Diabetes Cases')\n",
    "plt.show()\n",
    "\n",
    "# Pairplot to see relationships between features\n",
    "sns.pairplot(data, hue='Outcome')\n",
    "plt.show()\n",
    "\n",
    "# Define features and target variable\n",
    "X = data.drop('Outcome', axis=1)\n",
    "y = data['Outcome']\n",
    "\n",
    "# (Optional) Scale the features if necessary\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the decision tree classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plot_tree(dt_classifier, filled=True, feature_names=X.columns, class_names=['No Diabetes', 'Diabetes'])\n",
    "plt.title('Decision Tree for Diabetes Classification')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ca782c",
   "metadata": {},
   "outputs": [],
   "source": [
    "2. Glucose: Plasma glucose concentration a 2 hours in an oral glucose tolerance test (integer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce125937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics for the dataset\n",
    "print(data.describe())\n",
    "\n",
    "# Visualize the distribution of the Glucose variable\n",
    "sns.histplot(data['Glucose'], bins=30, kde=True)\n",
    "plt.title('Distribution of Plasma Glucose Concentration')\n",
    "plt.xlabel('Glucose Level')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Check for missing values in the Glucose column\n",
    "print(data['Glucose'].isnull().sum())\n",
    "\n",
    "# Impute missing values (if any) with the mean or median\n",
    "data['Glucose'].fillna(data['Glucose'].mean(), inplace=True)\n",
    "\n",
    "# Define features and target variable (including Glucose)\n",
    "X = data.drop('Outcome', axis=1)\n",
    "y = data['Outcome']\n",
    "\n",
    "# (Optional) Scale the features if necessary\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the decision tree classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plot_tree(dt_classifier, filled=True, feature_names=X.columns, class_names=['No Diabetes', 'Diabetes'])\n",
    "plt.title('Decision Tree for Diabetes Classification')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafd344f",
   "metadata": {},
   "outputs": [],
   "source": [
    "3. BloodPressure: Diastolic blood pressure (mm Hg) (integer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fb6bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the summary statistics for BloodPressure\n",
    "print(data['BloodPressure'].describe())\n",
    "\n",
    "# Visualize the distribution of the BloodPressure variable\n",
    "sns.histplot(data['BloodPressure'], bins=30, kde=True)\n",
    "plt.title('Distribution of Diastolic Blood Pressure')\n",
    "plt.xlabel('Blood Pressure (mm Hg)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Check for missing values in the BloodPressure column\n",
    "print(data['BloodPressure'].isnull().sum())\n",
    "\n",
    "# Impute missing values (if any) with the mean or median\n",
    "data['BloodPressure'].fillna(data['BloodPressure'].median(), inplace=True)\n",
    "\n",
    "# Define features and target variable (including BloodPressure)\n",
    "X = data.drop('Outcome', axis=1)  # Ensure all relevant features are included\n",
    "y = data['Outcome']\n",
    "\n",
    "# (Optional) Scale the features if necessary\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the decision tree classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plot_tree(dt_classifier, filled=True, feature_names=X.columns, class_names=['No Diabetes', 'Diabetes'])\n",
    "plt.title('Decision Tree for Diabetes Classification')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8eef4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "4. SkinThickness: Triceps skin fold thickness (mm) (integer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0af847a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the summary statistics for SkinThickness\n",
    "print(data['SkinThickness'].describe())\n",
    "\n",
    "# Visualize the distribution of the SkinThickness variable\n",
    "sns.histplot(data['SkinThickness'], bins=30, kde=True)\n",
    "plt.title('Distribution of Triceps Skin Fold Thickness')\n",
    "plt.xlabel('Skin Thickness (mm)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Check for missing values in the SkinThickness column\n",
    "print(data['SkinThickness'].isnull().sum())\n",
    "\n",
    "# Impute missing values (if any) with the median\n",
    "data['SkinThickness'].fillna(data['SkinThickness'].median(), inplace=True)\n",
    "\n",
    "# Define features and target variable (including SkinThickness)\n",
    "X = data.drop('Outcome', axis=1)  # Ensure all relevant features are included\n",
    "y = data['Outcome']\n",
    "\n",
    "# (Optional) Scale the features if necessary\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the decision tree classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plot_tree(dt_classifier, filled=True, feature_names=X.columns, class_names=['No Diabetes', 'Diabetes'])\n",
    "plt.title('Decision Tree for Diabetes Classification')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc974a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "5. Insulin: 2-Hour serum insulin (mu U/ml) (integer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad4fb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the summary statistics for Insulin\n",
    "print(data['Insulin'].describe())\n",
    "\n",
    "# Visualize the distribution of the Insulin variable\n",
    "sns.histplot(data['Insulin'], bins=30, kde=True)\n",
    "plt.title('Distribution of 2-Hour Serum Insulin Levels')\n",
    "plt.xlabel('Insulin (ÂµU/ml)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Check for missing values in the Insulin column\n",
    "print(data['Insulin'].isnull().sum())\n",
    "\n",
    "# Impute missing values (if any) with the median\n",
    "data['Insulin'].fillna(data['Insulin'].median(), inplace=True)\n",
    "\n",
    "# Define features and target variable (including Insulin)\n",
    "X = data.drop('Outcome', axis=1)  # Ensure all relevant features are included\n",
    "y = data['Outcome']\n",
    "\n",
    "# (Optional) Scale the features if necessary\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the decision tree classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plot_tree(dt_classifier, filled=True, feature_names=X.columns, class_names=['No Diabetes', 'Diabetes'])\n",
    "plt.title('Decision Tree for Diabetes Classification')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae30d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "6. BMI: Body mass index (weight in kg/(height in m)^2) (float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792fb7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the summary statistics for BMI\n",
    "print(data['BMI'].describe())\n",
    "\n",
    "# Visualize the distribution of the BMI variable\n",
    "sns.histplot(data['BMI'], bins=30, kde=True)\n",
    "plt.title('Distribution of Body Mass Index (BMI)')\n",
    "plt.xlabel('BMI')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Check for missing values in the BMI column\n",
    "print(data['BMI'].isnull().sum())\n",
    "\n",
    "# Impute missing values (if any) with the median\n",
    "data['BMI'].fillna(data['BMI'].median(), inplace=True)\n",
    "\n",
    "# Define features and target variable (including BMI)\n",
    "X = data.drop('Outcome', axis=1)  # Ensure all relevant features are included\n",
    "y = data['Outcome']\n",
    "\n",
    "# (Optional) Scale the features if necessary\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the decision tree classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plot_tree(dt_classifier, filled=True, feature_names=X.columns, class_names=['No Diabetes', 'Diabetes'])\n",
    "plt.title('Decision Tree for Diabetes Classification')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b1cca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "7. DiabetesPedigreeFunction: Diabetes pedigree function (a function which scores likelihood of diabetes\n",
    "based on family history) (float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc21bba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the summary statistics for Diabetes Pedigree Function\n",
    "print(data['DiabetesPedigreeFunction'].describe())\n",
    "\n",
    "# Visualize the distribution of the Diabetes Pedigree Function variable\n",
    "sns.histplot(data['DiabetesPedigreeFunction'], bins=30, kde=True)\n",
    "plt.title('Distribution of Diabetes Pedigree Function')\n",
    "plt.xlabel('Diabetes Pedigree Function Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Check for missing values in the DiabetesPedigreeFunction column\n",
    "print(data['DiabetesPedigreeFunction'].isnull().sum())\n",
    "\n",
    "# Impute missing values (if any) with the mean or median\n",
    "data['DiabetesPedigreeFunction'].fillna(data['DiabetesPedigreeFunction'].mean(), inplace=True)\n",
    "\n",
    "# Define features and target variable (including Diabetes Pedigree Function)\n",
    "X = data.drop('Outcome', axis=1)  # Ensure all relevant features are included\n",
    "y = data['Outcome']\n",
    "\n",
    "# (Optional) Scale the features if necessary\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the decision tree classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plot_tree(dt_classifier, filled=True, feature_names=X.columns, class_names=['No Diabetes', 'Diabetes'])\n",
    "plt.title('Decision Tree for Diabetes Classification')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043b2431",
   "metadata": {},
   "outputs": [],
   "source": [
    "8. Age: Age in years (integer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa51a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the summary statistics for Age\n",
    "print(data['Age'].describe())\n",
    "\n",
    "# Visualize the distribution of the Age variable\n",
    "sns.histplot(data['Age'], bins=30, kde=True)\n",
    "plt.title('Distribution of Age')\n",
    "plt.xlabel('Age (years)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Check for missing values in the Age column\n",
    "print(data['Age'].isnull().sum())\n",
    "\n",
    "# Impute missing values (if any) with the median\n",
    "data['Age'].fillna(data['Age'].median(), inplace=True)\n",
    "\n",
    "# Define features and target variable (including Age)\n",
    "X = data.drop('Outcome', axis=1)  # Ensure all relevant features are included\n",
    "y = data['Outcome']\n",
    "\n",
    "# (Optional) Scale the features if necessary\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the decision tree classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plot_tree(dt_classifier, filled=True, feature_names=X.columns, class_names=['No Diabetes', 'Diabetes'])\n",
    "plt.title('Decision Tree for Diabetes Classification')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4960ab73",
   "metadata": {},
   "outputs": [],
   "source": [
    "9. Outcome: Class variable (0 if non-diabetic, 1 if diabetic) (integer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c232a71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the distribution of the Outcome variable\n",
    "print(data['Outcome'].value_counts())\n",
    "\n",
    "# Visualize the distribution of the Outcome variable\n",
    "sns.countplot(x='Outcome', data=data)\n",
    "plt.title('Distribution of Diabetes Outcomes')\n",
    "plt.xlabel('Outcome (0: Non-diabetic, 1: Diabetic)')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# Define features (X) and target variable (y)\n",
    "X = data.drop('Outcome', axis=1)  # All features except Outcome\n",
    "y = data['Outcome']  # Outcome as the target variable\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the decision tree classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec25066",
   "metadata": {},
   "outputs": [],
   "source": [
    "Your goal is to create a decision tree to predict whether a patient has diabetes based on the other\n",
    "variables. Here are the steps you can follow:\n",
    "Q1. Import the dataset and examine the variables. Use descriptive statistics and visualizations to\n",
    "understand the distribution and relationships between the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bfeb919",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'diabetes.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Load the dataset\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiabetes.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Display the first few rows of the dataset\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(data\u001b[38;5;241m.\u001b[39mhead())\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1662\u001b[0m     f,\n\u001b[0;32m   1663\u001b[0m     mode,\n\u001b[0;32m   1664\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1665\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1666\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1667\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1668\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1669\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1670\u001b[0m )\n\u001b[0;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    860\u001b[0m             handle,\n\u001b[0;32m    861\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    862\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    863\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    864\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    865\u001b[0m         )\n\u001b[0;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'diabetes.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('diabetes.csv')\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(data.head())\n",
    "# Get information about the dataset\n",
    "print(data.info())\n",
    "\n",
    "# Check for missing values\n",
    "print(data.isnull().sum())\n",
    "# Get summary statistics for numerical features\n",
    "print(data.describe())\n",
    "# Set the style for the plots\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Plot distributions of features\n",
    "features = data.columns[:-1]  # All columns except 'Outcome'\n",
    "\n",
    "plt.figure(figsize=(15, 12))\n",
    "for i, feature in enumerate(features):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    sns.histplot(data[feature], bins=30, kde=True)\n",
    "    plt.title(f'Distribution of {feature}')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Visualize the relationship between each feature and the outcome\n",
    "plt.figure(figsize=(15, 12))\n",
    "for i, feature in enumerate(features):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    sns.boxplot(x='Outcome', y=feature, data=data)\n",
    "    plt.title(f'{feature} vs Outcome')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# Compute the correlation matrix\n",
    "correlation_matrix = data.corr()\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Draw the heatmap\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap='coolwarm', square=True, cbar_kws={\"shrink\": .8})\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e57959c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2. Preprocess the data by cleaning missing values, removing outliers, and transforming categorical\n",
    "variables into dummy variables if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8065b0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Impute missing values with the median for numerical features\n",
    "data.fillna(data.median(), inplace=True)\n",
    "# Function to remove outliers based on IQR\n",
    "def remove_outliers(df):\n",
    "    for column in df.select_dtypes(include=[np.number]).columns:\n",
    "        Q1 = df[column].quantile(0.25)\n",
    "        Q3 = df[column].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        df = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "    return df\n",
    "\n",
    "# Remove outliers from the dataset\n",
    "data = remove_outliers(data)\n",
    "\n",
    "# Check the shape of the data after outlier removal\n",
    "print(data.shape)\n",
    "# Example: If you had a categorical variable 'Gender'\n",
    "# data = pd.get_dummies(data, columns=['Gender'], drop_first=True)\n",
    "\n",
    "# Since our dataset doesn't contain categorical variables, this step can be skipped.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X = data.drop('Outcome', axis=1)  # Features\n",
    "y = data['Outcome']  # Target variable\n",
    "\n",
    "X_scaled = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36004185",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3. Split the dataset into a training set and a test set. Use a random seed to ensure reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34907ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Assuming you have your features in X and target in y\n",
    "X = data.drop('Outcome', axis=1)  # Features\n",
    "y = data['Outcome']  # Target variable\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Check the shape of the training and test sets\n",
    "print(f\"Training set shape: {X_train.shape}, Test set shape: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c76642",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4. Use a decision tree algorithm, such as ID3 or C4.5, to train a decision tree model on the training set. Use\n",
    "cross-validation to optimize the hyperparameters and avoid overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c680fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Define the parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'max_depth': [None, 5, 10, 15, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "}\n",
    "# Initialize the Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "# Set up GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=dt_classifier,\n",
    "                           param_grid=param_grid,\n",
    "                           scoring='accuracy',  # You can choose other metrics as needed\n",
    "                           cv=5,                # 5-fold cross-validation\n",
    "                           n_jobs=-1,          # Use all available cores\n",
    "                           verbose=1)          # Show progress\n",
    "\n",
    "# Fit the model to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "# Get the best parameters and score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "print(f\"Best cross-validated score: {best_score:.4f}\")\n",
    "# Initialize the Decision Tree Classifier with the best parameters\n",
    "best_dt_classifier = DecisionTreeClassifier(**best_params, random_state=42)\n",
    "\n",
    "# Fit the final model to the training data\n",
    "best_dt_classifier.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32d8d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5. Evaluate the performance of the decision tree model on the test set using metrics such as accuracy,\n",
    "precision, recall, and F1 score. Use confusion matrices and ROC curves to visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80ea171",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, roc_curve, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = best_dt_classifier.predict(X_test)\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "# Generate the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "            xticklabels=['Non-diabetic (0)', 'Diabetic (1)'],\n",
    "            yticklabels=['Non-diabetic (0)', 'Diabetic (1)'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()\n",
    "# Calculate probabilities for the positive class\n",
    "y_prob = best_dt_classifier.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Compute ROC curve and AUC\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "roc_auc = roc_auc_score(y_test, y_prob)\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label='ROC curve (area = {:.2f})'.format(roc_auc))\n",
    "plt.plot([0, 1], [0, 1], color='red', linestyle='--')  # Diagonal line\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ddce0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q6. Interpret the decision tree by examining the splits, branches, and leaves. Identify the most important\n",
    "variables and their thresholds. Use domain knowledge and common sense to explain the patterns and\n",
    "trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63847ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "\n",
    "# Plot the decision tree\n",
    "plt.figure(figsize=(12, 8))\n",
    "plot_tree(best_dt_classifier, filled=True, feature_names=X.columns, class_names=['Non-diabetic (0)', 'Diabetic (1)'], rounded=True)\n",
    "plt.title('Decision Tree for Diabetes Classification')\n",
    "plt.show()\n",
    "# Get feature importances\n",
    "importances = best_dt_classifier.feature_importances_\n",
    "\n",
    "# Create a DataFrame for visualization\n",
    "importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': importances})\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plot feature importances\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Importance', y='Feature', data=importance_df)\n",
    "plt.title('Feature Importances for Diabetes Classification')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455b58c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q7. Validate the decision tree model by applying it to new data or testing its robustness to changes in the\n",
    "dataset or the environment. Use sensitivity analysis and scenario testing to explore the uncertainty and\n",
    "risks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cfdafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming new_data is a DataFrame containing the same features as the training data\n",
    "new_data_predictions = best_dt_classifier.predict(new_data)\n",
    "\n",
    "# Evaluate performance metrics on new data\n",
    "new_accuracy = accuracy_score(new_data['Outcome'], new_data_predictions)\n",
    "print(f'New Data Accuracy: {new_accuracy:.4f}')\n",
    "# Add random noise to the features\n",
    "noise = np.random.normal(0, 0.1, X_test.shape)  # Adjust the standard deviation as needed\n",
    "X_test_noisy = X_test + noise\n",
    "\n",
    "# Make predictions on the noisy data\n",
    "noisy_predictions = best_dt_classifier.predict(X_test_noisy\n",
    "\n",
    "# Evaluate the performance on noisy data\n",
    "noisy_accuracy = accuracy_score(y_test, noisy_predictions)\n",
    "print(f'Accuracy with Noise: {noisy_accuracy:.4f}')\n",
    "# Example scenario testing: Create hypothetical patients\n",
    "scenarios = pd.DataFrame({\n",
    "    'Pregnancies': [0, 3, 5],\n",
    "    'Glucose': [70, 150, 200],\n",
    "    'BloodPressure': [60, 80, 90],\n",
    "    'SkinThickness': [10, 20, 30],\n",
    "    'Insulin': [0, 100, 200],\n",
    "    'BMI': [20.0, 30.0, 35.0],\n",
    "    'DiabetesPedigreeFunction': [0.5, 1.0, 1.5],\n",
    "    'Age': [25, 40, 60]\n",
    "})\n",
    "\n",
    "# Make predictions for these scenarios\n",
    "scenario_predictions = best_dt_classifier.predict(scenarios)\n",
    "\n",
    "# Print predictions for each scenario\n",
    "for i, pred in enumerate(scenario_predictions):\n",
    "    print(f'Scenario {i + 1}: Predicted Outcome = {pred}')\n",
    "# Function to assess sensitivity of predictions\n",
    "def sensitivity_analysis(feature, values):\n",
    "    results = []\n",
    "    for value in values:\n",
    "        temp_data = X_test.copy()\n",
    "        temp_data[feature] = value  # Change only the specified feature\n",
    "        pred = best_dt_classifier.predict(temp_data)\n",
    "        results.append(pred)\n",
    "    return results\n",
    "\n",
    "# Example: Sensitivity of predictions to changes in Glucose\n",
    "glucose_values = np.arange(50, 300, 10)  # Simulate glucose levels from 50 to 300\n",
    "sensitivity_results = sensitivity_analysis('Glucose', glucose_values)\n",
    "\n",
    "# Analyze results\n",
    "for value, preds in zip(glucose_values, sensitivity_results):\n",
    "    print(f'Glucose = {value}: Predicted Outcomes = {preds}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
